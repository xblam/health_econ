{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d53c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f99050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (8984, 105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R0000100</th>\n",
       "      <th>R0536401</th>\n",
       "      <th>R0536402</th>\n",
       "      <th>R1200300</th>\n",
       "      <th>R1235800</th>\n",
       "      <th>R2558800</th>\n",
       "      <th>R3880300</th>\n",
       "      <th>R4893600</th>\n",
       "      <th>R4893700</th>\n",
       "      <th>R4893800</th>\n",
       "      <th>...</th>\n",
       "      <th>U4370905</th>\n",
       "      <th>U4370906</th>\n",
       "      <th>U4958600</th>\n",
       "      <th>U5862900</th>\n",
       "      <th>U5862901</th>\n",
       "      <th>U5862902</th>\n",
       "      <th>U5862903</th>\n",
       "      <th>U5862904</th>\n",
       "      <th>U5862905</th>\n",
       "      <th>U5862906</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R0000100  R0536401  R0536402  R1200300  R1235800  R2558800  R3880300  \\\n",
       "0         1         9      1981         1         1         1         1   \n",
       "1         2         7      1982         1         1         1         1   \n",
       "2         3         9      1983         1         1         1         1   \n",
       "3         4         2      1981         1         1         1         1   \n",
       "4         5        10      1982         1         1         1         1   \n",
       "\n",
       "   R4893600  R4893700  R4893800  ...  U4370905  U4370906  U4958600  U5862900  \\\n",
       "0         3         3         3  ...        -5        -5        -5        -5   \n",
       "1         4         3         3  ...         0         0         0         0   \n",
       "2         4         2         4  ...         0         0         7         1   \n",
       "3         4         2         4  ...         0         0         3         0   \n",
       "4         4         2         2  ...         0         0         0         0   \n",
       "\n",
       "   U5862901  U5862902  U5862903  U5862904  U5862905  U5862906  \n",
       "0        -5        -5        -5        -5        -5        -5  \n",
       "1         0         0         0         0         0         0  \n",
       "2         1         1         0         3         0         1  \n",
       "3         0         0         3         0         0         0  \n",
       "4         0         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"health_econ_raw/raw_data.csv\")\n",
    "\n",
    "print(\"Raw shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452371e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = (\n",
    "    df.columns\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"-\", \"_\")\n",
    "        .str.replace(\"~\", \"_\")\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 3. Make names readable using pattern matching\n",
    "# ================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9768ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as clean_columns.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rename_dict = {\n",
    "    \"id\": \"id\",\n",
    "    \"r0536401\": \"birth_month\",\n",
    "    \"r0536402\": \"birth_year\",\n",
    "\n",
    "    # Regions\n",
    "    \"r1200300\": \"region_1997\",\n",
    "    \"r2558800\": \"region_1998\",\n",
    "    \"r3880300\": \"region_1999\",\n",
    "    \"r5459400\": \"region_2000\",\n",
    "    \"r7222400\": \"region_2001\",\n",
    "    \"s1535500\": \"region_2002\",\n",
    "    \"s2005400\": \"region_2003\",\n",
    "    \"s3805700\": \"region_2004\",\n",
    "    \"s5405600\": \"region_2005\",\n",
    "    \"s7506100\": \"region_2006\",\n",
    "    \"t0009400\": \"region_2007\",\n",
    "\n",
    "    # Income\n",
    "    \"r5464100\": \"income_2000\",\n",
    "    \"r7227800\": \"income_2001\",\n",
    "    \"s1541700\": \"income_2002\",\n",
    "    \"s2011500\": \"income_2003\",\n",
    "    \"s3812400\": \"income_2004\",\n",
    "    \"s5412800\": \"income_2005\",\n",
    "    \"s7513700\": \"income_2006\",\n",
    "    \"t0014100\": \"income_2007\",\n",
    "    \"t2016200\": \"income_2008\",\n",
    "    \"t3606500\": \"income_2009\",\n",
    "    \"t5206900\": \"income_2010\",\n",
    "\n",
    "    # MSA\n",
    "    \"r5473500\": \"msa_2000\",\n",
    "    \"r7237200\": \"msa_2001\",\n",
    "    \"s1552500\": \"msa_2002\",\n",
    "    \"s2022300\": \"msa_2003\",\n",
    "    \"s3823200\": \"msa_2004\",\n",
    "    \"s5423200\": \"msa_2005\",\n",
    "    \"s7525300\": \"msa_2006\",\n",
    "    \"t0025600\": \"msa_2007\",\n",
    "    \"t2020500\": \"msa_2008\",\n",
    "    \"t3611200\": \"msa_2009\",\n",
    "    \"t5211600\": \"msa_2010\",\n",
    "\n",
    "    # Urban-Rural\n",
    "    \"r5484100\": \"urban_rural_2000\",\n",
    "    \"r7248400\": \"urban_rural_2001\",\n",
    "    \"s1564300\": \"urban_rural_2002\",\n",
    "    \"s2034400\": \"urban_rural_2003\",\n",
    "    \"s3835800\": \"urban_rural_2004\",\n",
    "    \"s5436300\": \"urban_rural_2005\",\n",
    "    \"s7537100\": \"urban_rural_2006\",\n",
    "    \"t0033700\": \"urban_rural_2007\",\n",
    "    \"t2021300\": \"urban_rural_2008\",\n",
    "    \"t3612000\": \"urban_rural_2009\",\n",
    "    \"t5211900\": \"urban_rural_2010\",\n",
    "\n",
    "    # Migration history\n",
    "    \"r5532200\": \"migrate_01_2000\",\n",
    "    \"r5532300\": \"migrate_02_2000\",\n",
    "    \"r5532400\": \"migrate_03_2000\",\n",
    "    \"r5532500\": \"migrate_04_2000\",\n",
    "    \"r5532600\": \"migrate_05_2000\",\n",
    "    \"t5200700\": \"migrate_01_2010\",\n",
    "    \"t5200800\": \"migrate_02_2010\",\n",
    "    \"t5200900\": \"migrate_03_2010\",\n",
    "    \"t5201000\": \"migrate_04_2010\",\n",
    "    \"t5201100\": \"migrate_05_2010\",\n",
    "    \"t5201200\": \"migrate_06_2010\",\n",
    "\n",
    "    # Mental health (YSAQ)\n",
    "    \"r4893600\": \"nervous_2000\",\n",
    "    \"r4893700\": \"calm_2000\",\n",
    "    \"r4893800\": \"down_2000\",\n",
    "    \"r4893900\": \"happy_2000\",\n",
    "    \"r4894000\": \"depressed_2000\",\n",
    "\n",
    "    \"s0920800\": \"nervous_2002\",\n",
    "    \"s0920900\": \"calm_2002\",\n",
    "    \"s0921000\": \"down_2002\",\n",
    "    \"s0921100\": \"happy_2002\",\n",
    "    \"s0921200\": \"depressed_2002\",\n",
    "\n",
    "    \"s4681900\": \"nervous_2004\",\n",
    "    \"s4682000\": \"calm_2004\",\n",
    "    \"s4682100\": \"down_2004\",\n",
    "    \"s4682200\": \"happy_2004\",\n",
    "    \"s4682300\": \"depressed_2004\",\n",
    "\n",
    "    \"s8332300\": \"nervous_2006\",\n",
    "    \"s8332400\": \"calm_2006\",\n",
    "    \"s8332500\": \"down_2006\",\n",
    "    \"s8332600\": \"happy_2006\",\n",
    "    \"s8332700\": \"depressed_2006\",\n",
    "\n",
    "    \"t2782600\": \"nervous_2008\",\n",
    "    \"t2782700\": \"calm_2008\",\n",
    "    \"t2782800\": \"down_2008\",\n",
    "    \"t2782900\": \"happy_2008\",\n",
    "    \"t2783000\": \"depressed_2008\",\n",
    "\n",
    "    \"t6143700\": \"nervous_2010\",\n",
    "    \"t6143800\": \"calm_2010\",\n",
    "    \"t6143900\": \"down_2010\",\n",
    "    \"t6144000\": \"happy_2010\",\n",
    "    \"t6144100\": \"depressed_2010\",\n",
    "\n",
    "    # CESD scores\n",
    "    \"u3455400\": \"cesd_2019\",\n",
    "    \"u4958600\": \"cesd_2021\",\n",
    "\n",
    "    # CESD items\n",
    "    \"u4370900\": \"cesd_item1_2019\",\n",
    "    \"u4370901\": \"cesd_item2_2019\",\n",
    "    \"u4370902\": \"cesd_item3_2019\",\n",
    "    \"u4370903\": \"cesd_item4_2019\",\n",
    "    \"u4370904\": \"cesd_item5_2019\",\n",
    "    \"u4370905\": \"cesd_item6_2019\",\n",
    "    \"u4370906\": \"cesd_item7_2019\",\n",
    "\n",
    "    \"u5862900\": \"cesd_item1_2021\",\n",
    "    \"u5862901\": \"cesd_item2_2021\",\n",
    "    \"u5862902\": \"cesd_item3_2021\",\n",
    "    \"u5862903\": \"cesd_item4_2021\",\n",
    "    \"u5862904\": \"cesd_item5_2021\",\n",
    "    \"u5862905\": \"cesd_item6_2021\",\n",
    "    \"u5862906\": \"cesd_item7_2021\",\n",
    "}\n",
    "\n",
    "df = df.rename(columns=rename_dict)\n",
    "df.to_csv(\"health_econ_raw/clean_columns.csv\", index=False)\n",
    "print(\"Saved as clean_columns.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33732fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved event-study dataset!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"health_econ_raw/clean_columns.csv\")\n",
    "\n",
    "# ================================================================\n",
    "# 2. Identify year-specific columns\n",
    "# ================================================================\n",
    "\n",
    "# Region columns look like region_1997, region_1998, ...\n",
    "region_cols = [c for c in df.columns if c.startswith(\"region_\")]\n",
    "\n",
    "# Mental health (depressed_xxxx)\n",
    "mh_cols = [c for c in df.columns if c.startswith(\"depressed_\")]\n",
    "\n",
    "# Controls\n",
    "income_cols = [c for c in df.columns if c.startswith(\"income_\")]\n",
    "msa_cols = [c for c in df.columns if c.startswith(\"msa_\")]\n",
    "urban_cols = [c for c in df.columns if c.startswith(\"urban_rural_\")]\n",
    "\n",
    "# ================================================================\n",
    "# 3. Reshape from wide → long\n",
    "# ================================================================\n",
    "\n",
    "# We first melt each block, then merge them all\n",
    "def melt_panel(df, cols, varname):\n",
    "    long = df[[\"id\"] + cols].melt(\n",
    "        id_vars=\"id\", \n",
    "        value_vars=cols,\n",
    "        var_name=f\"{varname}_var\",\n",
    "        value_name=varname\n",
    "    )\n",
    "    # extract year from the column name\n",
    "    long[\"year\"] = long[f\"{varname}_var\"].str.extract(r\"(\\d{4})\").astype(int)\n",
    "    long = long.drop(columns=[f\"{varname}_var\"])\n",
    "    return long\n",
    "\n",
    "long_region = melt_panel(df, region_cols, \"region\")\n",
    "long_mh = melt_panel(df, mh_cols, \"depressed\")\n",
    "long_income = melt_panel(df, income_cols, \"income\")\n",
    "long_msa = melt_panel(df, msa_cols, \"msa\")\n",
    "long_urban = melt_panel(df, urban_cols, \"urban_rural\")\n",
    "\n",
    "# Merge all long datasets on id + year\n",
    "long = long_region.merge(long_mh, on=[\"id\",\"year\"], how=\"left\")\n",
    "long = long.merge(long_income, on=[\"id\",\"year\"], how=\"left\")\n",
    "long = long.merge(long_msa, on=[\"id\",\"year\"], how=\"left\")\n",
    "long = long.merge(long_urban, on=[\"id\",\"year\"], how=\"left\")\n",
    "\n",
    "# ================================================================\n",
    "# 4. Sort and create lagged region to detect moves\n",
    "# ================================================================\n",
    "long = long.sort_values([\"id\", \"year\"])\n",
    "\n",
    "# region_{t-1}\n",
    "long[\"region_lag\"] = long.groupby(\"id\")[\"region\"].shift(1)\n",
    "\n",
    "# Did region change?\n",
    "long[\"moved\"] = (long[\"region\"] != long[\"region_lag\"]).astype(int)\n",
    "long.loc[long[\"region_lag\"].isna(), \"moved\"] = 0  # first year cannot be move\n",
    "\n",
    "# Only count region moves (ignore missing)\n",
    "long[\"move_event\"] = np.where(\n",
    "    (long[\"moved\"] == 1) & (~long[\"region_lag\"].isna()),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 5. Count number of moves per person\n",
    "# ================================================================\n",
    "moves_per_id = long.groupby(\"id\")[\"move_event\"].sum().reset_index()\n",
    "moves_per_id.columns = [\"id\", \"num_moves\"]\n",
    "\n",
    "# Keep only one-time movers\n",
    "one_move_ids = moves_per_id[moves_per_id[\"num_moves\"] == 1][\"id\"]\n",
    "\n",
    "clean_long = long[long[\"id\"].isin(one_move_ids)]\n",
    "\n",
    "# ================================================================\n",
    "# 6. Get the move year for each ID\n",
    "# ================================================================\n",
    "move_years = (\n",
    "    clean_long[clean_long[\"move_event\"] == 1]\n",
    "    .groupby(\"id\")[\"year\"]\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "move_years.columns = [\"id\", \"move_year\"]\n",
    "\n",
    "clean_long = clean_long.merge(move_years, on=\"id\", how=\"left\")\n",
    "\n",
    "# ================================================================\n",
    "# 7. Create event-time variable (year - move_year)\n",
    "# ================================================================\n",
    "clean_long[\"event_time\"] = clean_long[\"year\"] - clean_long[\"move_year\"]\n",
    "\n",
    "# Optional: Keep only event_time in [-3, +3]\n",
    "clean_long = clean_long[(clean_long[\"event_time\"] >= -3) & \n",
    "                        (clean_long[\"event_time\"] <= 3)]\n",
    "\n",
    "# ================================================================\n",
    "# 8. Save final event-study dataset\n",
    "# ================================================================\n",
    "clean_long.to_csv(\"health_econ_raw/event_study_dataset.csv\", index=False)\n",
    "print(\"Saved event-study dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581846ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds30",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
